---
title: "Applied model specification"
author: 
    - Katie Schuler
date: 2024-10-08
---


Now that we've covered the terminology and concepts, let's apply model specification to some real models. 

```{r}
#| message: false

library(tidyverse)
library(mosaic)
```


## "Toy" data 


Let's start with the simplest possible example, a dataset with two data points. Suppose you record how many days you study over the next 5 days. On day 1, you study for 2 hours. On day 2, you study for 6 hours and so on. Your dataset might look something like this. 

::: {.panel-tabset}

### Plot



```{r}
#| echo: false
#| fig-height: 3
#| fig-width: 3

toy_data <- tibble(
  x = c(1, 2, 3, 4, 5), 
  y = c(2, 6, 7, 12, 13)
)

toy_data %>%
  ggplot(aes(x = x, y = y
  )) +
  geom_point() +
  theme_bw(base_size = 14) 

```


### Data

```{r}
#| echo: false
#| layout-ncol: 2

library(knitr)
kable(toy_data)
```


### Code

```r
toy_data <- tibble(
  x = c(1, 2, 3, 4, 5), 
  y = c(2, 6, 7, 12, 13)
)

toy_data %>%
  ggplot(aes(x = x, y = y)) +
  geom_point() +
  theme_bw(base_size = 14) 

```
:::

1. **Specify our response variable**, $y$: the response variable (🥸 data, output, prediction) is the variable you are trying to predict or explain with your model.
    - `y`

2. **Specify explantory variables**, $x_i$: the explanatory variables (🥸 regressors, inputs, predictors) are the predictors in your data that could help explain the response variable. Our data has only one possible: 
    - `x` 

3. **Specify the functional form**: the functional form describes the relationship between the response and explanatory variables with a mathematical expresson. In a linear model, we express this relationship as a weighted sum of inputs: 
    - $y=\sum_{i=1}^{n}w_ix_i$

4. **Specify model terms**: here we need to specify exactly *how* to express our explanatory variables in our functional form. The actual variables and constants that will be included in the model. There are four kinds of terms: (1) intercept, (2) main, (3) interaction, and (4) transformation. Here we have the simplest case of an intercept and one main term (no interactions or transformations necessary)
    - $y = w_1\mathbf{1} + w_2x_2$
    - in R: `y ~ 1 + x`

::: {.panel-tabset}

## Plot

:::: {.columns}
::: {.column width="50%"}


```{r}
#| echo: false
#| fig-height: 3
#| fig-width: 3

model <- lm(y ~ 1 + x, data = toy_data)

toy_data <- toy_data %>%
  mutate(with_formula = -0.4*1 + 2.8*x) %>%
  mutate(with_predict= predict(model, toy_data))

toy_data %>%
  ggplot(aes(x = x, y = y)) +
  geom_point() +
  geom_line(aes(y = with_predict), color = "blue") +
  theme_bw(base_size = 14) 

```

:::
::: {.column width="50%"}

Model specification: <br>
$y = w_1\cdot\mathbf{1} + w_2\cdot\mathbf{x}$

```{r}
#| echo: false

model
```

Fitted model: <br>
$y = -0.4\cdot1 + 2.8\cdot x$

:::
::::


## Data

```{r}
#| echo: false
#| layout-ncol: 2


kable(toy_data)
```


## Code

```r
model <- lm(y ~ 1 + x, data = toy_data)

toy_data <- toy_data %>%
  mutate(with_formula = -0.4*1 + 2.8*x) %>%
  mutate(with_predict= predict(model, toy_data))

toy_data %>%
  ggplot(aes(x = x, y = y)) +
  geom_point() +
  geom_line(aes(y = with_predict), color = "blue") +
  theme_bw(base_size = 14) 

```
:::

## Swim records

### One input

If our model has a single input, it is likely the intercept term, a constant (not variable) capturing the typical value of the response variable when all explanatory variables are zero. 


::: {.panel-tabset}

## Plot

:::: {.columns}
::: {.column width="50%"}


```{r}
#| echo: false
#| fig-height: 3
#| fig-width: 3

model <- lm(time ~ 1, data = SwimRecords)

SwimRecords_predict <- SwimRecords %>%
  mutate(with_formula = 59.92*1) %>%
  mutate(with_predict= predict(model, SwimRecords))

SwimRecords_predict %>%
  ggplot(aes(x = year, y = time)) +
  geom_point() +
  geom_line(aes(y = with_predict), color = "blue") +
  theme_bw(base_size = 14) 

```

:::
::: {.column width="50%"}

Model specification: <br>
$y = w_1\cdot\mathbf{1}$

```{r}
#| echo: false

model
```

Fitted model: <br>
$y = 59.92 \cdot 1$

:::
::::


## Data

```{r}
#| echo: false
#| layout-ncol: 2


library(knitr)
kable(SwimRecords_predict)
```


## Code

```r
model <- lm(time ~ 1, data = SwimRecords)

SwimRecords_predict <- SwimRecords %>%
  mutate(with_formula = 59.92*1) %>% 
  mutate(with_predict= predict(model, SwimRecords))

SwimRecords_predict %>%
  ggplot(aes(x = year, y = time)) +
  geom_point() +
  geom_line(aes(y = with_predict), color = "blue") +
  theme_bw(base_size = 14) 

```
:::


### Two inputs

We can add another term to our model represnting the effect of year on record time. This is a **main term** or **main effect**, which represents the effect of each explanatory variable on the response variable directly. In other words, how does record time change as a result of changes in year, when all other explanatory variables are zero? 

::: {.panel-tabset}

## Plot

:::: {.columns}
::: {.column width="50%"}


```{r}
#| echo: false
#| fig-height: 3
#| fig-width: 3

model <- lm(time ~ 1 + year, data = SwimRecords)

SwimRecords_predict <- SwimRecords %>%
  mutate(with_formula = 567.2420*1 + -0.2599*year) %>%
  mutate(with_predict= predict(model, SwimRecords))

SwimRecords_predict %>%
  ggplot(aes(x = year, y = time)) +
  geom_point() +
  geom_line(aes(y = with_predict), color = "blue") +
  theme_bw(base_size = 14) 

```

:::
::: {.column width="50%"}

Model specification: <br>
$y = w_1\cdot\mathbf{1} + w_2\cdot\mathbf{year}$

```{r}
#| echo: false

model
```

Fitted model: <br>
$y = 567.2420  \cdot \mathbf{1} + -0.2599 \cdot \mathbf{year}$

:::
::::


## Data

```{r}
#| echo: false
#| layout-ncol: 2


library(knitr)
kable(SwimRecords_predict)
```


## Code

```r
model <- lm(time ~ 1 + year, data = SwimRecords)

SwimRecords_predict <- SwimRecords %>%
  mutate(with_formula = 567.2420*1 + -0.2599*year) %>%
  mutate(with_predict= predict(model, SwimRecords))

SwimRecords_predict %>%
  ggplot(aes(x = year, y = time)) +
  geom_point() +
  geom_line(aes(y = with_predict), color = "blue") +
  theme_bw(base_size = 14) 

```
:::


### Three inputs

We can see that the previous model allowed us to capture the effect of year on record time, but we still have some unexplained variation. We can include sex in the model to capture the difference in record times by sex. 


::: {.panel-tabset}

## Plot

:::: {.columns}
::: {.column width="40%"}


```{r}
#| echo: false
#| fig-height: 3
#| fig-width: 3

model <- lm(time ~ 1 + year + sex, data = SwimRecords)

SwimRecords_predict <- SwimRecords %>%
  mutate(sex_numeric = case_when(
    sex == 'M' ~ 1,
    sex == 'F' ~ 0
  )) %>%
  mutate(with_formula = 555.7168*1 + -0.2515*year + -9.7980 *sex_numeric) %>%
  mutate(with_predict= predict(model, SwimRecords))

SwimRecords_predict %>%
  ggplot(aes(x = year, y = time, shape = sex)) +
  geom_point() +
  geom_line(aes(y = with_predict), color = "blue") +
  theme_bw(base_size = 14) 

```

:::
::: {.column width="60%"}

Model specification: <br>
$y = w_1\cdot\mathbf{1} + w_2\cdot\mathbf{year} + w_3\cdot\mathbf{sex}$

```{r}
#| echo: false

model
```

Fitted model: <br>
$y = 555.7168 \cdot \mathbf{1} + -0.2515 \cdot \mathbf{year} + -9.7980 \cdot \mathbf{sex}$

:::
::::


## Data

```{r}
#| echo: false
#| layout-ncol: 2


library(knitr)
kable(SwimRecords_predict)
```


## Code

```r
model <- lm(time ~ 1 + year + sex, data = SwimRecords)

SwimRecords_predict <- SwimRecords %>%
  mutate(sex_numeric = case_when(
    sex == 'M' ~ 1,
    sex == 'F' ~ 0
  )) %>%
  mutate(with_formula = 555.7168*1 + -0.2515*year + -9.7980 *sex_numeric) %>%
  mutate(with_predict= predict(model, SwimRecords))

SwimRecords_predict %>%
  ggplot(aes(x = year, y = time, shape = sex)) +
  geom_point() +
  geom_line(aes(y = with_predict), color = "blue") +
  theme_bw(base_size = 14) 

```
:::


### Interaction 

Notice that the previous model now gets us record times getting faster by year, and different predictions for men and women (women have slower times). But this is missing another relationship we can see in our data: that women are getting faster, faster. To express that the effect of one explanatory variable on the response variable is different at different values of another explanatory variable (e.g. the effect of year on record times is different for men and women), we add a term to the model in which we multiply the values of the interacting variables.

*We could say that we "expand the input space" of the model, since we add terms to capture the interaction*

::: {.panel-tabset}

## Plot

:::: {.columns}
::: {.column width="40%"}


```{r}
#| echo: false
#| fig-height: 3
#| fig-width: 3

model <- lm(time ~ 1 + year * sex, data = SwimRecords)

SwimRecords_predict <- SwimRecords %>%
  mutate(with_predict= predict(model, SwimRecords))

SwimRecords_predict %>%
  ggplot(aes(x = year, y = time, shape = sex)) +
  geom_point() +
  geom_line(aes(y = with_predict), color = "blue") +
  theme_bw(base_size = 14) 

```

:::
::: {.column width="60%"}

Model specification: <br>
$y = w_1\cdot\mathbf{1} + w_2\cdot\mathbf{year} + w_3\cdot\mathbf{sex} + w_4\cdot\mathbf{year\times{sex}}$

```{r}
#| echo: false

model
```

Fitted model: <br>
\begin{align}
y = &697.3012 \cdot \mathbf{1} + -0.3240 \cdot \mathbf{year} + -302.4638 \cdot \mathbf{sex}\\
&+ 0.1499 \cdot \mathbf{year\times{sex}}
\end{align}

:::
::::


## Data

```{r}
#| echo: false
#| layout-ncol: 2


library(knitr)
kable(SwimRecords_predict)
```


## Code

```r
model <- lm(time ~ 1 + year * sex, data = SwimRecords)

SwimRecords_predict <- SwimRecords %>%
  mutate(with_predict= predict(model, SwimRecords))

SwimRecords_predict %>%
  ggplot(aes(x = year, y = time, shape = sex)) +
  geom_point() +
  geom_line(aes(y = with_predict), color = "blue") +
  theme_bw(base_size = 14) 

```
:::


### Transformation 

Now our model is doing a great job at predicting our data, but there may be more we want to do. For example, we can see that the model is not predicting women very well around the year 2000 (it is predicting they will be faster than they are). If we want to allow the model to have a curve shape, capturing that women gained on men for a while, but are no slowing down, we can add a term to the model in which we square the year. This allows us to capture this nonlinear curve or bend in the data (more on this for polynomials in the next section). 

*but notice that the model is fitting the data well, but still behaving a bit non-sensical toward the 2000s, predicint that record times are getter slower! Impossible!)*

::: {.panel-tabset}

## Plot

:::: {.columns}
::: {.column width="40%"}


```{r}
#| echo: false
#| fig-height: 3
#| fig-width: 3

model <- lm(time ~ 1 + year * sex + I(year^2), data = SwimRecords)

SwimRecords_predict <- SwimRecords %>%
  mutate(with_predict= predict(model, SwimRecords))

SwimRecords_predict %>%
  ggplot(aes(x = year, y = time, shape = sex)) +
  geom_point() +
  geom_line(aes(y = with_predict), color = "blue") +
  theme_bw(base_size = 14) 

```

:::
::: {.column width="60%"}

Model specification: <br>
\begin{align}
y = &w_1\cdot\mathbf{1} + w_2\cdot\mathbf{year} + w_3\cdot\mathbf{sex} \\
&+ w_4\cdot\mathbf{year\times{sex}} +w_5\cdot\mathbf{year}^2
\end{align}

```{r}
#| echo: false

model
```

Fitted model: <br>
\begin{align}
y = &11100 \cdot \mathbf{1} + -10.98 \cdot \mathbf{year} + -317.1 \cdot \mathbf{sex}\\
&+ 0.1575 \cdot \mathbf{year\times{sex}} + 0.002729 \cdot \mathbf{year}^2
\end{align}

:::
::::


## Data

```{r}
#| echo: false
#| layout-ncol: 2


library(knitr)
kable(SwimRecords_predict)
```


## Code

```r
model <- lm(time ~ 1 + year * sex + I(year^2), data = SwimRecords)

SwimRecords_predict <- SwimRecords %>%
  mutate(with_predict= predict(model, SwimRecords))

SwimRecords_predict %>%
  ggplot(aes(x = year, y = time, shape = sex)) +
  geom_point() +
  geom_line(aes(y = with_predict), color = "blue") +
  theme_bw(base_size = 14) 

```
:::

## Linearizing nonlinear models 

When you want to linearlize a nonlinear model, you're trying to fit a linear model to data that doesn't naturally follow a straight line. There are two common ways to approach this: 

1. **Expanding the input space** with polynomials. Polynomials can capture "bumps" or curves in the data. In this approach, we **add terms** to the model, like squares or cubes of the original variable. 
    - $y = w_1 + w_2x + w_3x^2$

2. **Transforming the data** involves applying mathematical functions to existing inputs to alter their scale or distributions. Common transformations include taking the logarithm or square root. Taking the logarithm of a variable compresses its range and reduces skewness in the data (as in the brain size and body weight data). 
    - both output and input: $log(y) = w_1 + w_2 log(x)$ 
    - just input: $y = w_1 + w_2 log(x)$

## Plant heights (polynomials)

Polynomials capture "bumps" or curves in the data, and the number of these bumps depends on the **degree** of the polynomial. The higher the degree, the more complex the shape the polynomial can represent. 

![](/assests/images/polynomials.png)


- **Degree 1 (Linear)**: A straight line. There are no bumps or curves. The relationship between the predictor and the response is either increasing or decreasing at a constant rate.
- **Degree 2 (Quadratic)**: A single bump or curve. The graph is either a U-shape (bowl) or an upside-down U-shape (hill), meaning it can capture one turning point.
- **Degree 3 (Cubic)**: Can capture two bumps (or one “S” shaped curve). The graph can have two turning points, meaning it can start by increasing, then decrease, and increase again (or the opposite).
- **Degree 4 (Quartic)**: Can capture three bumps or changes in direction. The graph can have up to three turning points, allowing for more complex shapes and curves in the data.

### Degree 1 (Linear)

Remember, a **Degree 1 (Linear)** is a straight line. There are no bumps or curves. The relationship between the predictor and the response is either increasing or decreasing at a constant rate. This doesn't seem to capture the relationship between light_exposure and plant_height in our data. 

::: {.panel-tabset}

## Plot

:::: {.columns}
::: {.column width="50%"}


```{r}
#| echo: false
#| message: false
#| fig-height: 3
#| fig-width: 3

poly_plants <- read_csv('https://kathrynschuler.com/datasci/assests/csv/polynomial_plants.csv')

model <- lm(plant_height ~ 1 + light_exposure, data = poly_plants)

poly_plants <- poly_plants %>%
  mutate(with_formula = 31.346*1 + 3.619*light_exposure) %>%
  mutate(with_predict= predict(model, poly_plants))

poly_plants %>%
  ggplot(aes(x = light_exposure, y = plant_height)) +
  geom_point() +
  geom_line(aes(y = with_predict), color = "blue") +
  theme_bw(base_size = 14) 

```

:::
::: {.column width="50%"}

Model specification: <br>
$y = w_1\cdot\mathbf{1} + w_2 \cdot \mathbf{x}$

```{r}
#| echo: false

model
```

Fitted model: <br>
$y = 31.346 \cdot 1 + 3.619 \cdot x$

:::
::::


## Data

```{r}
#| echo: false
#| layout-ncol: 2


kable(poly_plants)
```


## Code

```r
poly_plants <- read_csv('https://kathrynschuler.com/datasci/assests/csv/polynomial_plants.csv')

model <- lm(plant_height ~ 1 + light_exposure, data = poly_plants)

poly_plants <- poly_plants %>%
  mutate(with_formula = 31.346*1 + 3.619*light_exposure) %>%
  mutate(with_predict= predict(model, poly_plants))

poly_plants %>%
  ggplot(aes(x = light_exposure, y = plant_height)) +
  geom_point() +
  geom_line(aes(y = with_predict), color = "blue") +
  theme_bw(base_size = 14) 

```
:::

### Degree 2 (Quadratic)

In a **Degree 2 (Quadratic)** polynomial, we can express a single bump or curve. The graph is either a U-shape (bowl) or an upside-down U-shape (hill), meaning it can capture one turning point. This provides a better fit for our data, allow us to express the light exposure goes up and then back down again. But it looks like there is another "bump" in the data, going back upward around light exposure of 1 or 2.

::: {.panel-tabset}

## Plot

:::: {.columns}
::: {.column width="50%"}


```{r}
#| echo: false
#| message: false
#| fig-height: 3
#| fig-width: 3

poly_plants <- read_csv('https://kathrynschuler.com/datasci/assests/csv/polynomial_plants.csv')

model <- lm(plant_height ~ 1 + light_exposure + I(light_exposure^2), data = poly_plants)

poly_plants <- poly_plants %>%
  mutate(with_predict= predict(model, poly_plants))

poly_plants %>%
  ggplot(aes(x = light_exposure, y = plant_height)) +
  geom_point() +
  geom_line(aes(y = with_predict), color = "blue") +
  theme_bw(base_size = 14) 

```

:::
::: {.column width="50%"}

Model specification: <br>
$y = w_1\cdot\mathbf{1} + w_2 \cdot \mathbf{x} + w_3 \cdot \mathbf{x}^2$


```{r}
#| echo: false

model
```

Fitted model: <br>
$y = -9.245 \cdot\mathbf{1} + 27.973 \cdot \mathbf{x} + -2.214  \cdot \mathbf{x}^2$

:::
::::


## Data

```{r}
#| echo: false
#| layout-ncol: 2


kable(poly_plants)
```


## Code

```r

model <- lm(plant_height ~ 1 + light_exposure + I(light_exposure^2), data = poly_plants)

poly_plants <- poly_plants %>%
  mutate(with_predict= predict(model, poly_plants))

poly_plants %>%
  ggplot(aes(x = light_exposure, y = plant_height)) +
  geom_point() +
  geom_line(aes(y = with_predict), color = "blue") +
  theme_bw(base_size = 14) 

```
:::

### Degree 3 (Cubic)

In a **Degree 3 (Cubic)** polynomial, we can capture two bumps (or one “S” shaped curve). The graph can have two turning points, meaning it can start by increasing, then decrease, and increase again (or the opposite). This captures the data quite nicely. 

::: {.panel-tabset}

## Plot

:::: {.columns}
::: {.column width="50%"}


```{r}
#| echo: false
#| message: false
#| fig-height: 3
#| fig-width: 3

poly_plants <- read_csv('https://kathrynschuler.com/datasci/assests/csv/polynomial_plants.csv')

model <- lm(plant_height ~ 1 + light_exposure + I(light_exposure^2) + I(light_exposure^3), data = poly_plants)

poly_plants <- poly_plants %>%
  mutate(with_predict= predict(model, poly_plants))

poly_plants %>%
  ggplot(aes(x = light_exposure, y = plant_height)) +
  geom_point() +
  geom_line(aes(y = with_predict), color = "blue") +
  theme_bw(base_size = 14) 

```

:::
::: {.column width="50%"}

Model specification: <br>
$y = w_1\cdot\mathbf{1} + w_2 \cdot \mathbf{x} + w_3 \cdot \mathbf{x}^2 + w_4 \cdot \mathbf{x}^3$


```{r}
#| echo: false

model
```

Fitted model: <br>
$y = 8.7363 \cdot \mathbf{1} + 2.7276  \cdot \mathbf{x} + 3.7796 \cdot \mathbf{x}^2 + -0.3632  \cdot \mathbf{x}^3$

:::
::::


## Data

```{r}
#| echo: false
#| layout-ncol: 2


kable(poly_plants)
```


## Code

```r
model <- lm(plant_height ~ 1 + light_exposure + I(light_exposure^2) + I(light_exposure^3), data = poly_plants)

poly_plants <- poly_plants %>%
  mutate(with_predict= predict(model, poly_plants))

poly_plants %>%
  ggplot(aes(x = light_exposure, y = plant_height)) +
  geom_point() +
  geom_line(aes(y = with_predict), color = "blue") +
  theme_bw(base_size = 14) 

```
:::


## Brain size (log)


### Untransformed

When we have a nonlinear relationship, as here, we could just try to fit a linear model to the untransformed data. It *techincally* works — there is no math reason that prevents us from fitting this model — but we can see that it is a very bad description of the data. 

::: {.panel-tabset}

## Plot

:::: {.columns}
::: {.column width="50%"}


```{r}
#| echo: false
#| message: false
#| fig-height: 3
#| fig-width: 3

brain_data <- read_csv('https://kathrynschuler.com/datasci/assests/csv/animal_brain_body_size.csv') %>%
  rename(brain_size_cc = `Brain Size (cc)`, body_size_kg = `Body Size (kg)`)

model <- lm(brain_size_cc ~ 1 + body_size_kg, data = brain_data)

brain_data <- brain_data %>%
  mutate(with_predict= predict(model, brain_data))

brain_data %>%
  ggplot(aes(x = body_size_kg, y = brain_size_cc)) +
  geom_point() +
  geom_line(aes(y = with_predict), color = "blue") +
  theme_bw(base_size = 14) 

```

:::
::: {.column width="50%"}

Model specification: <br>
$y = w_1\cdot\mathbf{1} + w_2\cdot\mathbf{body\_size\_kg}$

```{r}
#| echo: false

model
```

Fitted model: <br>
$y = 816.59014 \cdot\mathbf{1} + 0.05021 \cdot\mathbf{body\_size\_kg}$

:::
::::


## Data

```{r}
#| echo: false
#| layout-ncol: 2


kable(brain_data)
```


## Code

```r
brain_data <- read_csv('https://kathrynschuler.com/datasci/assests/csv/animal_brain_body_size.csv') %>%
  rename(brain_size_cc = `Brain Size (cc)`, body_size_kg = `Body Size (kg)`)

model <- lm(brain_size_cc ~ 1 + body_size_kg, data = brain_data)

brain_data <- brain_data %>%
  mutate(with_predict= predict(model, brain_data))

brain_data %>%
  ggplot(aes(x = body_size_kg, y = brain_size_cc)) +
  geom_point() +
  geom_line(aes(y = with_predict), color = "blue") +
  theme_bw(base_size = 14) 

```
:::

### Log transformed

We can apply a log transform directly in the model specification provided to R. This works great, but if we try to plot the fitted model on untransformed data (e.g. if we use brain_size_cc and body_size_kg as our y and x aesthetics) something doesn't seem quite right. Instead, we should plot the data transformed to log as well, so the model predictions match the data. 

::: {.panel-tabset}

## Plot

:::: {.columns}
::: {.column width="50%"}


```{r}
#| echo: false
#| message: false
#| fig-height: 3
#| fig-width: 3

brain_data <- read_csv('https://kathrynschuler.com/datasci/assests/csv/animal_brain_body_size.csv') %>%
  rename(brain_size_cc = `Brain Size (cc)`, body_size_kg = `Body Size (kg)`)

model <- lm(log(brain_size_cc) ~ 1 + log(body_size_kg), data = brain_data)

brain_data <- brain_data %>%
  mutate(
    log_brain_size_cc = log(brain_size_cc), 
    log_body_size_kg = log(body_size_kg)
  ) %>%
  mutate(with_predict= predict(model, brain_data))

brain_data %>%
  ggplot(aes(x = log_body_size_kg, y = log_brain_size_cc)) +
  geom_point() +
  geom_line(aes(y = with_predict), color = "blue") +
  theme_bw(base_size = 14) 

```

:::
::: {.column width="50%"}

Model specification: <br>
$log(y) = w_1\cdot\mathbf{1} + w_2 \cdot log(\mathbf{body\_size\_kg})$

```{r}
#| echo: false

model
```

Fitted model: <br>
$log(y) = 2.2042\cdot\mathbf{1} + 0.6687 \cdot log(\mathbf{body\_size\_kg})$


:::
::::


## Data

```{r}
#| echo: false
#| layout-ncol: 2


kable(brain_data)
```


## Code

```r
model <- lm(log(brain_size_cc) ~ 1 + log(body_size_kg), data = brain_data)

brain_data <- brain_data %>%
  mutate(
    log_brain_size_cc = log(brain_size_cc), 
    log_body_size_kg = log(body_size_kg)
  ) %>%
  mutate(with_predict= predict(model, brain_data))

brain_data %>%
  ggplot(aes(x = log_body_size_kg, y = log_brain_size_cc)) +
  geom_point() +
  geom_line(aes(y = with_predict), color = "blue") +
  theme_bw(base_size = 14) 

```
:::




## Further reading

- [Ch 6: Language of models](https://dtkaplan.github.io/SM2-bookdown/language-of-models.html) in Statistical Modeling

